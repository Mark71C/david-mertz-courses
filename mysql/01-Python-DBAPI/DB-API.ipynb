{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"position: relative;\">\n",
    "<img src=\"https://user-images.githubusercontent.com/7065401/98728503-5ab82f80-2378-11eb-9c79-adeb308fc647.png\"></img>\n",
    "\n",
    "<h1 style=\"color: white; position: absolute; top:27%; left:10%;\">\n",
    "    MySQL and MariaDB for Python Developers\n",
    "</h1>\n",
    "\n",
    "<h3 style=\"color: #ef7d22; font-weight: normal; position: absolute; top:55%; left:10%;\">\n",
    "    David Mertz, Ph.D.\n",
    "</h3>\n",
    "\n",
    "<h3 style=\"color: #ef7d22; font-weight: normal; position: absolute; top:62%; left:10%;\">\n",
    "    Data Scientist\n",
    "</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python DB-API\n",
    "\n",
    "Python defines a standard interface for all SQL relational database system, called the DB-API.  Most database drivers within the Python ecosystem follow this API standard; any features specific to a particular Relational Database Management System (RDBMS), such as MySQL, are communicated at the SQL level rather than with special Python methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python Enhancement Proposal (PEP) 249 describes the requirements of the DB-API 2.0.  Details of the degree of support and choice among optional features are exposed in module interfaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapter capabilities\n",
    "\n",
    "For comparison, let us inspect adapters to an SQLite database and a MySQL database.  Some parameters are coded compactly.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| threadsafety | Meaning\n",
    "|-------------:|:--------------------------------------\n",
    "| 0            | Threads may not share the module.\n",
    "| 1            | Threads may share the module, but not connections.\n",
    "| 2            | Threads may share the module and connections.\n",
    "| 3            | Threads may share the module, connections and cursors.\n",
    "\n",
    "---\n",
    "\n",
    "| paramstyle | Meaning\n",
    "|-----------:|:----------------------------------------\n",
    "| qmark      | Question mark style, e.g. ...WHERE name=?\n",
    "| numeric    | Numeric, positional style, e.g. ...WHERE name=:1\n",
    "| named      | Named style, e.g. ...WHERE name=:name\n",
    "| format     | ANSI C printf format codes, e.g. ...WHERE name=%s\n",
    "| pyformat   | Python extended format codes, e.g. ...WHERE name=%(name)s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API level       | 2.0\n",
      "Parameter style | qmark\n",
      "Thread safety   | 1\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "print(f\"API level       | {sqlite3.apilevel}\")\n",
    "print(f\"Parameter style | {sqlite3.paramstyle}\")\n",
    "print(f\"Thread safety   | {sqlite3.threadsafety}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API level       | 2.0\n",
      "Parameter style | pyformat\n",
      "Thread safety   | 1\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "print(f\"API level       | {mysql.connector.apilevel}\")\n",
    "print(f\"Parameter style | {mysql.connector.paramstyle}\")\n",
    "print(f\"Thread safety   | {mysql.connector.threadsafety}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the server\n",
    "\n",
    "Before you get started with the steps in the lesson, you will need to configure your MySQL or MariaDB server as an administrator.  Specifically, we need to run these SQL commands to create the user and database we will work as:\n",
    "\n",
    "```sql\n",
    "CREATE DATABASE ine;\n",
    "CREATE USER 'ine_student'@'localhost' IDENTIFIED BY 'ine-password';\n",
    "GRANT ALL PRIVILEGES ON ine.* TO 'ine_student'@'localhost';\n",
    "```\n",
    "\n",
    "If the server is on a remote machine, a host address other than `localhost` will be needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A connection and cursors\n",
    "\n",
    "We can see from the threadsafety level our `mysql.connector` adaptor provides, that we can create a single connection for all the threads we may wish to use.  The cursors should remain distinct between threads.  This lesson will not use Python threading, which is a separate course, but we can create multiple cursors in the main thread, if we wish.  For this lesson, we simply assume that a database called `ine` exists, and the MySQL user and password configured will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'ine_student'\n",
    "pwd = 'ine-password'\n",
    "host = 'localhost'\n",
    "port = '3306'\n",
    "db = 'ine'\n",
    "conn = mysql.connector.connect(database=db, host=host, user=user, password=pwd, port=port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it is convenient, we can work with multiple cursor.  Keep in mind, however, that performing a commit or a rollback will happen at the connection level.  However, it may be useful, for example, to create temporary cursors within a function, and only pass around a connection object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main action we peform with a cursor is to `.execute()` SQL statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the table with cursor#1\n",
    "sql_create = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS users (\n",
    "  user_id SERIAL PRIMARY KEY,\n",
    "  username VARCHAR(50) UNIQUE NOT NULL,\n",
    "  password VARCHAR(50) NOT NULL,\n",
    "  age SMALLINT,\n",
    "  created_on TIMESTAMP NOT NULL\n",
    ");\n",
    "\"\"\"\n",
    "cur.execute(sql_create)\n",
    "# Remove any rows if table had existed\n",
    "cur.execute(\"DELETE FROM users;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MySQL allows an SQL extension of `IF NOT EXISTS` in SQL statements.  The table may or may not have existed initially, but this will not fail if it did.  However, if a table already exists, a second `CREATE TABLE` with this option will ignore the field names and data types in the new SQL statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the table has not actually been created, but rather the action has been placed in the transaction queue.  It may or may not be committed.  In fact, if we attempt to commit it, it is *possible* that some other action by another connection would be inconsistent with this, and the transaction would be rolled back.  In this case, and most cases, a commit will succeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described, a `CREATE TABLE IF NOT EXISTS` can succeed at the query level, but not alter a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_bad_create = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS users (\n",
    "  not_an_id SERIAL PRIMARY KEY,\n",
    "  not_a_user INTEGER UNIQUE NOT NULL,\n",
    "  not_a_password VARCHAR(30) NOT NULL\n",
    ");\n",
    "\"\"\"\n",
    "cur.execute(sql_bad_create)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the table structure using a query, and verify which version exists in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user_id', 'bigint', None, None, 'NO'),\n",
       " ('username', 'varchar', 50, None, 'NO'),\n",
       " ('password', 'varchar', 50, None, 'NO'),\n",
       " ('age', 'smallint', None, None, 'YES'),\n",
       " ('created_on', 'timestamp', None, None, 'NO')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_schema = \"\"\"\n",
    "SELECT column_name, data_type, character_maximum_length, \n",
    "       column_default, is_nullable\n",
    "FROM INFORMATION_SCHEMA.COLUMNS \n",
    "WHERE table_name = 'users';\n",
    "\"\"\"\n",
    "cur.execute(sql_schema)\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with data\n",
    "\n",
    "With the table we created above, let us write some data to it.  Remember that the `mysql.connector` adapter uses the `pyformat` parameter style.  Note also that MySQL is only thread-safe in sharing the adapter module, but not in sharing the connections.  To handle that, we might create a *connection pool* to draw from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "pool = Queue(maxsize=5)  # Keep around 5 connections objects\n",
    "for _ in range(5):\n",
    "    conn = mysql.connector.connect(\n",
    "                database=db, host=host, user=user, password=pwd, port=port)\n",
    "    pool.put(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A thread-safe function utilizing the pool can add users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from threading import Thread\n",
    "\n",
    "def add_user(pool, user):\n",
    "    # Need to get a connection from the pool\n",
    "    conn = pool.get()\n",
    "    cursor = conn.cursor()\n",
    "    user['now'] = datetime.now().isoformat()\n",
    "    user['age'] = user.get('age')\n",
    "    sql = \"\"\"INSERT INTO users (username, password, age, created_on) \n",
    "             VALUES (%(username)s, %(password)s, %(age)s, %(now)s)\"\"\"\n",
    "    cursor.execute(sql, user)\n",
    "    # When we are done with connection, put it back in the pool\n",
    "    pool.put(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call this function with user data a few times, each in a separate thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_info = [\n",
    "  dict(username='Alice', password='bad_pw_1', age=37),\n",
    "  dict(username='Bob', password='bad_pw_2'),\n",
    "  dict(username='Carlos', password='bad_pw_3', age=62)\n",
    "]\n",
    "for user_info in users_info:\n",
    "    t = Thread(target=add_user, args=(pool, user_info))\n",
    "    t.start()\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, so good.  However, these data have not actually been stored in the database, only queued as a transaction.  The global cursor, from the connection not from the pool, cannot see them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id', 'username', 'password', 'age', 'created_on']\n",
      "-----\n",
      "Tuples:\n"
     ]
    }
   ],
   "source": [
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT * FROM users;\")\n",
    "print([f[0] for f in cur.description])\n",
    "print('-----\\nTuples:')\n",
    "for row in cur:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the data available to all connections, we want to commit it.  However, since we are using a thread pool, we want to get all the connections to commit.  This could be simpler if we know we will only will use single threading; but the approach here can allow scaling to heavier load, if we need it.  For writing a small number of rows at a time, the threaded approach is overhead without gain; in other scenarios it can be a huge improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commit_all(pool):\n",
    "    for _ in range(pool.qsize()):\n",
    "        conn = pool.get()\n",
    "        conn.commit()\n",
    "        pool.put(conn)\n",
    "\n",
    "commit_all(pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking again, we see our committed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id', 'username', 'password', 'age', 'created_on']\n",
      "-----\n",
      "Tuples:\n",
      "(1, 'Alice', 'bad_pw_1', 37, datetime.datetime(2021, 1, 9, 22, 19, 3))\n",
      "(2, 'Bob', 'bad_pw_2', None, datetime.datetime(2021, 1, 9, 22, 19, 3))\n",
      "(3, 'Carlos', 'bad_pw_3', 62, datetime.datetime(2021, 1, 9, 22, 19, 3))\n"
     ]
    }
   ],
   "source": [
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT * FROM users;\")\n",
    "print([f[0] for f in cur.description])\n",
    "print('-----\\nTuples:')\n",
    "for row in cur:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncommitted data\n",
    "\n",
    "A batch of SQL statements may not succeed.  In such a case, we may not wish for *any* of them to be recorded.  In such a case, we want to call `.rollback()` on the connection to inform the server to discard the transaction from the queue.  We might rollback because of a problem the server reports, or we may do so because of something we determine at an application level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_many(pool, users_info):\n",
    "    sql = \"\"\"INSERT INTO users (username, password, age, created_on) \n",
    "         VALUES (%(username)s, %(password)s, %(age)s, %(now)s)\"\"\"\n",
    "    try:\n",
    "        conn = pool.get()\n",
    "        cur = conn.cursor()\n",
    "        for user in users_info:\n",
    "            if 'password' in user['password']:\n",
    "                raise ValueError(f\"Terrible password for {user['username']}\")\n",
    "            user['age'] = user.get('age')   # Default to None if not age\n",
    "            user['now'] = datetime.now().isoformat()\n",
    "        # Insert batch all at once\n",
    "        cur.executemany(sql, users_info)\n",
    "    except Exception as err:\n",
    "        conn.rollback()\n",
    "        print(\"Transaction rolled back because of:\", type(err).__name__)\n",
    "        print(err)\n",
    "        return False\n",
    "    else:\n",
    "        conn.commit()\n",
    "        return True\n",
    "    finally:\n",
    "        pool.put(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps the datatypes are wrong:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction rolled back because of: DatabaseError\n",
      "1366 (HY000): Incorrect integer value: 'ABC' for column 'age' at row 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_bad_data = [\n",
    "    dict(username='Dave', password='insecure_1'),\n",
    "    dict(username='Erin', password='insecure_2'),\n",
    "    dict(username='Faythe', password='insecure_3', age=\"ABC\")\n",
    "]\n",
    "add_many(pool, users_bad_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or perhaps a uniqueness constraint is violated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction rolled back because of: IntegrityError\n",
      "1062 (23000): Duplicate entry 'Carlos' for key 'users.username'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_dup_data = [\n",
    "    dict(username='Dave', password='insecure_1'),\n",
    "    dict(username='Erin', password='insecure_2'),\n",
    "    dict(username='Carlos', password='bad_pw_4')\n",
    "]\n",
    "add_many(pool, users_dup_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or it might be that the application itself is able to exclude some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction rolled back because of: ValueError\n",
      "Terrible password for Ivan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_app_rules = [\n",
    "    dict(username='Grace', password='insecure_77'),\n",
    "    dict(username='Heidi', password='insecure_88'),\n",
    "    dict(username='Ivan', password='password_55')\n",
    "]\n",
    "add_many(pool, users_app_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working in batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the last few cells, we will configure the connection to AUTOCOMMIT.  That is, every time an insertion is made, a COMMIT is implictly performed afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.autocommit = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen several ways to fetch the results from a query.  We can use `.fetchone()`, or `.fetchmany()`, or `.fetchall()`.  We can also loop over the cursor object to bind each row, or using the same Python iterator protocol, call `next(cursor)`.\n",
    "\n",
    "A similar capability is available for excucting statements.  In concept, this could be many SELECT queries, but more commonly, it is many INSERT or UPDATE commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now().isoformat()\n",
    "users_more = [\n",
    "    dict(username='Sybil', password='M7c&sd31&0hA', age=44, created_on=now),\n",
    "    dict(username='Trudy', password='y9bD6SA2O%$t', age=22, created_on=now),\n",
    "    dict(username='Vanna', password='9$Ts9HK*3!tR', age=55, created_on=now)\n",
    "]\n",
    "sql = \"\"\"\n",
    "INSERT INTO users (username, password, age, created_on) \n",
    "VALUES (%(username)s, %(password)s, %(age)s, %(created_on)s)\n",
    "\"\"\"\n",
    "cur.executemany(sql, users_more)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, you probably want to catch exceptions and do conditional rollbacks and remediation around your `.executemany()` calls.  But we assume it succeeded, and was automatically committed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying it again, we can explicitly ask for details on the columns returned by a query, and the number of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('user_id', 8, None, None, None, None, 0, 49703)\n",
      "('username', 253, None, None, None, None, 0, 20485)\n",
      "('age', 2, None, None, None, None, 1, 32768)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 'Alice', 37),\n",
       " (2, 'Bob', None),\n",
       " (3, 'Carlos', 62),\n",
       " (10, 'Sybil', 44),\n",
       " (11, 'Trudy', 22),\n",
       " (12, 'Vanna', 55)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('SELECT user_id, username, age FROM users;')\n",
    "for item in cur.description:\n",
    "    print(item)\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to notice is that the SERIAL `user_id` column was incremented on the various failures that were not committed.  This makes sense since a unique sequential number has to be assigned before the server can know whether that transaction will be committed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the particular adapter, the `cursor.rowcount` attribute will either return an advanced indicator of how much is available, or in the case of `mysql.connector`, only return how many were actually fetched.  E.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Alice\n",
      "2 Bob\n",
      "3 Carlos\n",
      "4 Sybil\n",
      "5 Trudy\n",
      "6 Vanna\n"
     ]
    }
   ],
   "source": [
    "cur.execute('SELECT username FROM users;')\n",
    "for name in cur:\n",
    "    print(cur.rowcount, name[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "To use adapters that follow the DB-API requires learning only a few fairly simple APIs, while offering flexibility at the Python level.  Once you have mastered that, everything else you really need to know is specific to MySQL as an RDBMS, and is accessed via SQL interfaces rather than Python functions or methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
