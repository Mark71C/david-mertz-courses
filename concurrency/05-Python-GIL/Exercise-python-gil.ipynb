{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "This exercise will be somewhat different from those in other lessons.  We will continue to use the same basic premise of creating multiple files, each containing 20 Natural Numbers.  For this exercise, we again generate 1000 of them.  However, since the Global Interpreter lock is a design feature of CPython itself rather than an API provided, it makes less sense to program according to some API or pattern to dive deeper into this lesson.\n",
    "\n",
    "The largest lesson of this lesson is probably that I/O bound code \"releases the GIL\" and will often benefit from threading on multiple cores.  CPU bound code, in contrast, is, in pure Python, can only be concurrent, not truly parallel.\n",
    "\n",
    "Let us return to the exercise in lesson 3 which asked you to read in all 1000 files with names like `tmp-?????.numbers` and perform an accumulation across corresponding lines of each file (considering them in alphabetical order).  The essence of the algorithm was provided in the solution.  It assumes that you have read a given line number of each of the 1000 files into a list of 1000 integers.  So, for each line 17, for example, we calculate:\n",
    "\n",
    "```python\n",
    "top = ((99 + 99) * 99) ** 99  # modulo bigger than any number\n",
    "data = line17_numbers + [top]\n",
    "accum = data[0]\n",
    "for j in range(1, len(data), 4):\n",
    "    b, c, d, e = data[j:j+4]\n",
    "    accum = (((accum + b) * c) ** d) % e\n",
    "```\n",
    "\n",
    "There is no need even to use the `threading` module for this exercise.  You simply want to evaluate how much time is spent in the I/O operations (reading from 1000 files) versus how much is spent in the mathematical operations.  This answer will vary depending on the kind of CPU and kind of disk that exists on the machine where you run this exercise.  Write general functions `time_io()` and `time_cpu()` simply to return two numbers estimating those times in microseconds.  This will give you some sense of the theoretically best possible thread parallelism in pure-Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate import create_files\n",
    "create_files('lesson-5')\n",
    "\n",
    "def time_io():\n",
    "    return 50_000   # microseconds\n",
    "\n",
    "def time_cpu():\n",
    "    return 50_000   # microseconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from glob import glob\n",
    "from statistics import median\n",
    "from random import randint\n",
    "\n",
    "def time_io():\n",
    "    times = []\n",
    "    files = glob('tmp-*.numbers')\n",
    "    for _ in range(11):  # Typical read (try several times)\n",
    "        start = time()\n",
    "        for fname in files:\n",
    "            numbers = open(fname).readlines()\n",
    "        times.append(time()-start)\n",
    "        \n",
    "    return int(median(times) * 1_000_000)\n",
    "\n",
    "def time_cpu():\n",
    "    times = []\n",
    "    top = ((99 + 99) * 99) ** 99 \n",
    "    for _ in range(20):  # Simulate the 20 lines\n",
    "        # Perhaps different numbers change timing significantly\n",
    "        data = [randint(1, 99) for _ in range(1000)] + [top]\n",
    "        accum = data[0]\n",
    "        start = time()\n",
    "        for j in range(1, len(data), 4):\n",
    "            b, c, d, e = data[j:j+4]\n",
    "            accum = (((accum + b) * c) ** d) % e\n",
    "        times.append(time()-start) \n",
    "        \n",
    "    return int(sum(times) * 1_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_plausible_io():\n",
    "    assert 1000 < time_io() < 100_000\n",
    "    \n",
    "test_plausible_io()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_plausible_cpu():\n",
    "    assert 1000 < time_cpu() < 100_000\n",
    "    \n",
    "test_plausible_cpu()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
