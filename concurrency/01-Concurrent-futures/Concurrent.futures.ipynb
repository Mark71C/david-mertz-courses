{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Concurrent.futures\n",
    "\n",
    "In this lesson, we jump immediately to the highest-level abstraction for concurrency that the Python standard library provides: the `concurrent.futures` module.  \n",
    "\n",
    "Some of the terms presented here may not be entirely familiar yet, but I believe you can understand them in context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Most** of the time, when you write concurrent programs in Python, you should use `concurrent.futures`.  \n",
    "\n",
    "The module provides a beautiful and Pythonic interface that makes concurrency easy, while hiding most of the messy details of threads, processes, locks, deadlocks, race conditions, data sharing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "...Of course, most of the time is not **all** of the time.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You will sometimes need to reach down to lower-level interfaces provided by other modules that `concurrent.futures` is built on top of.  Those building blocks make up the remaining lessons of this course.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It might be wise to return to this lesson at the end, after you have completed the other lessons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallel and Sequential\n",
    "\n",
    "The problems that `concurrent.futures` best addresses are ones that are *embarrassingly parallel* (or nearly so).  If you can express your problems as a large number of \"tasks\" each of which is already bundled with the data it needs, concurrency is easiest.  \n",
    "\n",
    "On the other hand, if every task depends on the result of its predecessor, a program is *strictly sequential*.  Many real computations are somewhere in the middle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example: Embarrassingly Parallel\n",
    "\n",
    "Problems that are embarrassingly parallel include Monte Carlo simulations, web scraping or distributed data acquisition, many types of graphic rendering (with pixels independent), and other domains.\n",
    "\n",
    "A diagram of such tasks might look like this (an arrow indicates one task depends on the output of another task).\n",
    "\n",
    "<img src=\"embarrasingly-parallel.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example: Strictly Sequential\n",
    "\n",
    "Other problems are sequential by nature, and cannot be made concurrent in any meaningful way.  \n",
    "\n",
    "For example, most pseudo-random number generators keep internal state, and perform a complex mathematical modification of that state each time they move to the next state (typically not reversibly, but that is inessential here).\n",
    "\n",
    "<img src=\"strictly-sequential.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example: Mixed Data Flow\n",
    "\n",
    "Many problems fall between these two pictures.  Some tasks have sequential dependencies, but others are independent.  \n",
    "\n",
    "For example, perhaps you have to aggregate and process per-second data sequentially for a day, but then you need to reaggregate daily data into decades in a s similar way.  Some things can be concurrent, but others are dependencies.\n",
    "\n",
    "<img src=\"mixed-data-flow.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let us load the various modules and names we use in this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#----- Concurrency facilities\n",
    "from concurrent.futures import (\n",
    "    ThreadPoolExecutor, ProcessPoolExecutor, TimeoutError, as_completed)\n",
    "from multiprocessing import cpu_count\n",
    "from threading import current_thread\n",
    "from queue import Queue, SimpleQueue, Empty\n",
    "#----- General utilities\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "from pprint import pprint\n",
    "from time import sleep\n",
    "from collections import namedtuple\n",
    "from random import sample\n",
    "#----- Some pretty display later\n",
    "from ipywidgets import IntProgress, Layout, Label\n",
    "from IPython.display import display\n",
    "#----- Used in various examples\n",
    "base_url = \"http://localhost:5000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Executors\n",
    "\n",
    "Executors are the main construct in `concurrent.futures`. They are similar to `multiprocessing.Pool`, which we look at in a later lesson. Once an executor has been instantiated, we can `submit` jobs, or even `map` tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the module are two executors: `ThreadPoolExecutor` and `ProcessPoolExecutor`. They have the same interface, but use different concurrency mechanisms.  The trade-offs of processes and threads are discussed in later lessons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We need to define a task to perform, using a Python callable.  For this lesson, we use a server that reports hisorical cryptocurrency prices on different markets.  The server takes about a second to return a response to each query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def check_price(exchange, symbol, date):\n",
    "    url = f\"{base_url}/price/{exchange}/{symbol}/{date}\"\n",
    "    resp = requests.get(url)\n",
    "    return resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.63 ms, sys: 0 ns, total: 6.63 ms\n",
      "Wall time: 723 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6421.14"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "data = check_price('bitstamp', 'btc', '2020-04-01')\n",
    "data['close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can call the function, with given arguments by wrapping it in an executor.  There is no advantage in doing so for a single function call, but it is a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price: $6421.14\n",
      "CPU times: user 10.3 ms, sys: 0 ns, total: 10.3 ms\n",
      "Wall time: 719 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Default max_workers is 5 x #cores\n",
    "with ThreadPoolExecutor(max_workers=10) as ex:\n",
    "    future = ex.submit(check_price, 'bitstamp', 'btc', '2020-04-01')\n",
    "    data = future.result()\n",
    "    \n",
    "print(f\"Price: ${data['close']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Or with identical interface, use a process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'close': 6421.14,\n",
      " 'day': '2020-04-01',\n",
      " 'exchange': 'bitstamp',\n",
      " 'high': 6527.24,\n",
      " 'low': 6337.42,\n",
      " 'open': 6408.95,\n",
      " 'symbol': 'btc',\n",
      " 'volume': 6342.29832651}\n",
      "\n",
      "CPU times: user 44.3 ms, sys: 33.2 ms, total: 77.5 ms\n",
      "Wall time: 838 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Default max_workers is just number of cores for processes\n",
    "with ProcessPoolExecutor(max_workers=cpu_count()) as ex:\n",
    "    future = ex.submit(check_price, 'bitstamp', 'btc', '2020-04-01')\n",
    "    pprint(future.result())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Futures\n",
    "\n",
    "In the examples above, the `submit` method immediately returns a `Future` object. These objects are an abstraction of a task that is being processed. \n",
    "\n",
    "They have multiple useful methods; the most important is `.result(timeout=None)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The `timeout` argument lets us wait a finite number of seconds until a result is produced. If no result is generated in that time, a `TimeoutError` is raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeoutError()\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ex = ThreadPoolExecutor()\n",
    "    future = ex.submit(check_price, 'bitstamp', 'btc', '2020-04-01')\n",
    "    data = future.result(timeout=0.5)\n",
    "except TimeoutError as err:\n",
    "    pprint(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Another important method of a `Future` is `.done()`.  Notice that we might submit multiple tasks, and each might become \"done\" afer different durations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just submitted: done? False\n",
      "Slept a while: done? True\n",
      "Bitstamp price: $6421.14\n",
      "Kraken price: $6401.9\n",
      "Waited on result: done? True\n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor() as ex:\n",
    "    future1 = ex.submit(check_price, 'bitstamp', 'btc', '2020-04-01')\n",
    "    future2 = ex.submit(check_price, 'kraken', 'btc', '2020-04-01')\n",
    "    print(\"Just submitted: done?\", future1.done())\n",
    "    sleep(3)\n",
    "    print(\"Slept a while: done?\", future1.done())\n",
    "    print(f\"Bitstamp price: ${future1.result()['close']}\")\n",
    "    print(f\"Kraken price: ${future2.result()['close']}\")\n",
    "    print(\"Waited on result: done?\", future1.done())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Executor .map()\n",
    "\n",
    "While you can perfectly well call `.submit()` manually to create many futures, very often it is easier and more clear to create an entire family of implicit futures for different data you wish to process concurrently.  \n",
    "\n",
    "When using `.map()` to create families of workers, you may only pass a single argument.  This simply means you have to package each *data value* into a collection like a tuple or dictionary that can be destructured within the worker function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def check_price(data):\n",
    "    exchange, symbol, date = data\n",
    "    url = f\"{base_url}/price/{exchange}/{symbol}/{date}\"\n",
    "    resp = requests.get(url)\n",
    "    return resp.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When you call `.map()` it is as if you called `.result()` on each future, although the futures are not named."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 records retrieved\n",
      "[6409.8, 133, 39.076, 6630.8, 135.49, 39.356, 6803.9, '...']\n",
      "CPU times: user 139 ms, sys: 18.3 ms, total: 157 ms\n",
      "Wall time: 817 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "datasets = []\n",
    "for exchange in ['bitfinex', 'bitstamp', 'kraken']:\n",
    "    for date in ['2020-04-01', '2020-04-02', '2020-04-03', '2020-04-04']:\n",
    "        for coin in ['btc', 'eth', 'ltc']:\n",
    "            datasets.append((exchange, coin, date))\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=100) as ex:\n",
    "    results = ex.map(check_price, datasets)\n",
    "    prices = [price['close'] for price in results]\n",
    "    print(f\"{len(prices)} records retrieved\")\n",
    "    print(prices[:7] + [\"...\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Futures as_completed()\n",
    "\n",
    "The `.map()` method is very concise for mapping one function to multiple data sets it should process.  It *did* require us to refactor the function to unpack a single *data* object.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A bit more flexible is using the function `as_completed()` to iterate over results as they become available.  This will block on the next result becoming available, but the threads or processes generating those results will keep running while your code handles an available one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 records retrieved\n",
      "CPU times: user 125 ms, sys: 61.5 ms, total: 186 ms\n",
      "Wall time: 874 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with ThreadPoolExecutor(max_workers=100) as ex:\n",
    "    # Could add futures with different function/arguments\n",
    "    futures = {ex.submit(check_price, data): None for data in datasets}\n",
    "    records = []\n",
    "    for future in as_completed(futures):\n",
    "        records.append(future.result())\n",
    "        \n",
    "print(f\"{len(records)} records retrieved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Producer/Consumer Pattern\n",
    "\n",
    "What we did so far supposed that we knew the data associated with our overall processing in advance of launching workers.  That will not always be the case; in particular, some workers may generate the data for other workers to process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The trick to allowing this setup is the use of **queues** (or a similar data structure) that allow safe concurrent access.  A queue allows one worker to push data into a collection, and another worker to pop data, without risking one overwriting the other or other data integrity problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We will extend the example of querying prices from exchanges, but with the addition of a **producer** that generates requests at the same time as other **consumers** are processing them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The architecture of this example is a bit more detailed, to resemble real programs you will write.  We will launch three types of workers as part of this overall system.\n",
    "\n",
    "* A **monitor** that will simply show the evolving queues\n",
    "* A **producer** that will feed requests into the TODO queue\n",
    "* Multiple **consumers** that will act on requests, and add to the RESULTS queue\n",
    "\n",
    "Let us first create the queues that the tasks will work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Q_todo, Q_results, Q_info = Queue(), SimpleQueue(), SimpleQueue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "While it might be more robust to put the initial introspection of the server into a concurrent task, here we simplify slightly and perform this small task in a non-concurrent way first.  The server can report what exchanges and symbols are available for querying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023 total queries will be performed\n"
     ]
    }
   ],
   "source": [
    "# Find exchanges and symbols from the server\n",
    "exchanges = requests.get(f\"{base_url}/exchanges\").json()\n",
    "symbols = requests.get(f\"{base_url}/symbols\").json()\n",
    "\n",
    "# Choose the dates of interest ourselves\n",
    "dates, start = [], datetime(2020, 3, 1) \n",
    "for i in range(31):\n",
    "    date = start + timedelta(days=i)\n",
    "    dates.append(date.strftime('%Y-%m-%d'))\n",
    "\n",
    "nreqs = len(exchanges) * len(dates) * len(symbols)\n",
    "print(f\"{nreqs} total queries will be performed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Next let us define the monitor that reports progress. This uses some magic with IPython widgets that are not the subject of this lesson; do not worry about those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def monitor(Q_todo, Q_results, Q_info):\n",
    "    # Create the visual monitor widgets\n",
    "    todo = IntProgress(value=0, min=0, max=nreqs, step=1, description='TODO', \n",
    "                orientation='horizontal', bar_style='info', layout=Layout(width='50%'))\n",
    "    done = IntProgress(value=0, min=0, max=nreqs, step=1, description='DONE', \n",
    "                orientation='horizontal', bar_style='success', layout=Layout(width='50%'))\n",
    "    info = Label(value='STARTING...')\n",
    "    display(todo); display(done); display(info)\n",
    "    \n",
    "    while True:\n",
    "        todo.value = Q_todo.qsize()\n",
    "        done.value = Q_results.qsize()\n",
    "        try:\n",
    "            info.value = f\"{Q_info.get(timeout=3)}\"\n",
    "        except Empty:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We need to create a producer function that will feed queries into the TODO queue.  In this case, the data involved is a small tuple of query elements; in other cases, the data itself might be substantial (such as a numeric array or a large text).  This producer artificially limits the rate at which it adds to the queue just to simulate real-world applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def producer(Q_todo, Q_info, exchanges, dates, symbols):\n",
    "    Query = namedtuple('Query', 'exchange date symbol')\n",
    "    for exchange in exchanges:\n",
    "        for date in dates:\n",
    "            for symbol in symbols:\n",
    "                query = Query(exchange, symbol, date)\n",
    "                Q_todo.put(query)\n",
    "                Q_info.put(f\"ADDING {query}\")\n",
    "                sleep(0.015)  # Artificial small delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally, in our task scaffolding is the worker function.  This worker consumes unprocessed queries from the TODO queue, operates on them, and puts the result in the RESULTS queue.  The RESULTS queue is a regular `Queue` rather than a `SimpleQueue` because a worker will mark the query as processed at the end of its work, using the `.task_done()` method (not available in `SimpleQueue`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def worker(Q_todo, Q_results, Q_info):\n",
    "    thread = current_thread().name\n",
    "    sleep(0.5)  # Let TODO queue get populated first\n",
    "    while not Q_todo.empty():\n",
    "        query = Q_todo.get()\n",
    "        Q_info.put(f\"PROCESSING {query}\")\n",
    "        result = check_price(query)\n",
    "        Q_results.put(result)\n",
    "        Q_todo.task_done()\n",
    "        \n",
    "    Q_info.put(f\"EXITING {thread} (TODO queue empty)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Putting it together, let us launch our concurrent processing using many threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d3c542a9dc404aa955c3bb9f3a4f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, bar_style='info', description='TODO', layout=Layout(width='50%'), max=1023)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6caa59929ea8406793c010330acd321e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, bar_style='success', description='DONE', layout=Layout(width='50%'), max=1023)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0536501d35194208bac0fdfbc145477d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='STARTING...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.9 s, sys: 1.58 s, total: 13.5 s\n",
      "Wall time: 28.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Q_todo, Q_results, Q_info = Queue(), SimpleQueue(), SimpleQueue()\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=100) as ex:\n",
    "    futures = []\n",
    "    futures.append(ex.submit(producer, Q_todo, Q_info, exchanges, dates, symbols))\n",
    "    futures.append(ex.submit(monitor, Q_todo, Q_results, Q_info))\n",
    "    for _ in range(32):\n",
    "        futures.append(ex.submit(worker, Q_todo, Q_results, Q_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Having run our processing across concurrent workers, for this purpose, we have accumulated all the results in the RESULTS queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All futures done? True\n",
      "Size of TODO: 0\n",
      "Size of RESULTS: 1023\n",
      "Size of INFO: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"All futures done?\", all([f.done() for f in futures]))\n",
    "print(\"Size of TODO:\", Q_todo.qsize())\n",
    "print(\"Size of RESULTS:\", Q_results.qsize())\n",
    "print(\"Size of INFO:\", Q_info.qsize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "From the queue, we might want to pull the results into random access data structure.  For a few hundred elements, certainly this is convenient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for _ in range(Q_results.qsize()):\n",
    "    result = Q_results.get()\n",
    "    results.append(result)\n",
    "    Q_results.put(result)   # Put the result back at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'exchange': 'okex',\n",
       "  'symbol': 'eth',\n",
       "  'open': 135.91,\n",
       "  'high': 145,\n",
       "  'low': 132.49,\n",
       "  'close': 138.42,\n",
       "  'volume': 796791.072558,\n",
       "  'day': '2020-03-25'},\n",
       " {'exchange': 'okex',\n",
       "  'symbol': 'btc',\n",
       "  'open': 5028,\n",
       "  'high': 5527.9,\n",
       "  'low': 4923.7,\n",
       "  'close': 5314.1,\n",
       "  'volume': 95054.82617103,\n",
       "  'day': '2020-03-18'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(results, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "The `concurrent.futures` module is the most abstract, highest-level concurrency module in the Python standard library. It **should be** your default option when writing concurrent code.  \n",
    "\n",
    "Only when you need more advanced capabilities, will you need to use the `threading` or `multiprocessing` modules directly."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
