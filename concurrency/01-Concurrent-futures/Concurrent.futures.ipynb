{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Concurrent.futures\n",
    "\n",
    "In this lesson, we jump immediately to the highest-level abstraction for concurrency that the Python standard library provides: the `concurrent.futures` module.  Some of the terms presented here may not be entirely familiar yet, but I believe you can understand them in context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Most** of the time, when you write concurrent programs in Python, you should use `concurrent.futures`.  It provides a beautiful and Pythonic interface that makes concurrency easy, while hiding most of the messy details of threads, processes, locks, deadlocks, race conditions, data sharing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Of course, most of the time is not **all** of the time.  You will sometimes need to reach down to lower-level interfaces provided by other modules that `concurrent.futures` is built on top of.  Those building blocks make up the remaining lessons of this course.  It might be wise to return to this lesson at the end, after you have completed the other lessons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallel and Sequential\n",
    "\n",
    "The problems that `concurrent.futures` best addresses are ones that are *embarrassingly parallel* (or nearly so).  If you can express your problems as a large number of \"tasks\" each of which is already bundled with the data it needs, concurrency is easiest.  On the other hand, if every task depends on the result of its predecessor, a program is *strictly sequential*.  Many real computations are somewhere in the middle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example: Embarrassingly Parallel\n",
    "\n",
    "Problems that are embarrassingly parallel include Monte Carlo simulations, web scraping or distributed data acquisition, many types of graphic rendering (with pixels independent), and other domains.  A diagram of such tasks might look like (an arrow indicates one task depends on the output of another task).\n",
    "\n",
    "<img src=\"embarrasingly-parallel.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example: Strictly Sequential\n",
    "\n",
    "Other problems are sequential by nature, and cannot be made concurrent in any meaningful way.  For example, most pseudo-random number generators keep internal state, and perform a complex mathematical modification of that state each time they move to the next state (typically not reversibly, but that is inessential here).\n",
    "\n",
    "<img src=\"strictly-sequential.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example: Mixed Data Flow\n",
    "\n",
    "Many problems fall between these two pictures.  Some tasks have sequential dependencies, but others are independent.  For example, perhaps you have to aggregate and process per-second data sequentially for a day, but then you need to reaggregate daily data into decades in a s similar way.  Some things can be concurrent, but others are dependencies.\n",
    "\n",
    "<img src=\"mixed-data-flow.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let us load the various modules and names we use in this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import concurrent.futures as cf\n",
    "import queue\n",
    "import multiprocessing as mp\n",
    "from threading import current_thread\n",
    "from queue import Queue, SimpleQueue, Empty\n",
    "from concurrent.futures import (\n",
    "    ThreadPoolExecutor, ProcessPoolExecutor, TimeoutError)\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "from pprint import pprint\n",
    "from time import sleep\n",
    "from collections import namedtuple\n",
    "from random import sample\n",
    "\n",
    "# Some pretty display later\n",
    "from ipywidgets import IntProgress, Layout, Label\n",
    "from IPython.display import display\n",
    "\n",
    "# Used in various examples\n",
    "base_url = \"http://localhost:5000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Executors\n",
    "\n",
    "Executors are the main construct in `concurrent.futures`. They are similar to `multiprocessing.Pool`, which we look at in a later lesson. Once an executor has been instantiated, we can `submit` jobs, or even `map` tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The abstract class `concurrent.futures.Executor` that has two concrete children: `ThreadPoolExecutor` and `ProcessPoolExecutor`. We use same interface to each, but use different concurrency mechanisms by changing the executor type.  The trade-offs of processes and threads are discussed in later lessons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The first thing we need to do is define a task to perform, which is some sort of Python callable.  For the example, we look at a hypothetical ticker to a cryptocurrency market.  The important thing here is simply that the server takes about a second to return a response to each query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def check_price(exchange, symbol, date):\n",
    "    url = f\"{base_url}/price/{exchange}/{symbol}/{date}\"\n",
    "    resp = requests.get(url)\n",
    "    return resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.9 ms, sys: 5.5 ms, total: 22.3 ms\n",
      "Wall time: 1.25 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6421.14"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "data = check_price('bitstamp', 'btc', '2020-04-01')\n",
    "data['close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can call the function, with given arguments by wrapping it in an executor.  There is no advantage in doing so for a single function call, but it is a starting point.  We can use a thread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price: $6421.14\n",
      "CPU times: user 9.83 ms, sys: 5.2 ms, total: 15 ms\n",
      "Wall time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Default max_workers is 5 x cores-on-machine\n",
    "with ThreadPoolExecutor(max_workers=10) as ex:\n",
    "    future = ex.submit(check_price, 'bitstamp', 'btc', '2020-04-01')\n",
    "    data = future.result()\n",
    "    \n",
    "print(f\"Price: ${data['close']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Or with identical interface, use a process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'close': 6421.14,\n",
      " 'day': '2020-04-01',\n",
      " 'exchange': 'bitstamp',\n",
      " 'high': 6527.24,\n",
      " 'low': 6337.42,\n",
      " 'open': 6408.95,\n",
      " 'symbol': 'btc',\n",
      " 'volume': 6342.29832651}\n",
      "\n",
      "CPU times: user 36.8 ms, sys: 61.5 ms, total: 98.3 ms\n",
      "Wall time: 1.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Default max_workers is just number of cores for processes\n",
    "with ProcessPoolExecutor(max_workers=mp.cpu_count()) as ex:\n",
    "    future = ex.submit(check_price, 'bitstamp', 'btc', '2020-04-01')\n",
    "    pprint(future.result())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Futures\n",
    "\n",
    "In the examples above, the `submit` method immediately returns a `Future` object. These objects are an abstraction of a task that is being processed. They have multiple useful methods; the most important is `.result(timeout=None)`. \n",
    "\n",
    "The `timeout` argument lets us wait a finite number of seconds until a result is produced. If no result is generated in that time, a `TimeoutError` is raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeoutError()\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ex = ThreadPoolExecutor()\n",
    "    future = ex.submit(check_price, 'bitstamp', 'btc', '2020-04-01')\n",
    "    data = future.result(timeout=1)\n",
    "except TimeoutError as err:\n",
    "    pprint(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Another important method of a `Future` is `.done()`.  Notice that we might submit multiple tasks, and each might become \"done\" afer different durations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just submitted: done? False\n",
      "Slept a while: done? True\n",
      "Bitstamp price: $6421.14\n",
      "Kraken price: $6401.9\n",
      "Waited on result: done? True\n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor() as ex:\n",
    "    future1 = ex.submit(check_price, 'bitstamp', 'btc', '2020-04-01')\n",
    "    future2 = ex.submit(check_price, 'kraken', 'btc', '2020-04-01')\n",
    "    print(\"Just submitted: done?\", future1.done())\n",
    "    sleep(3)\n",
    "    print(\"Slept a while: done?\", future1.done())\n",
    "    print(f\"Bitstamp price: ${future1.result()['close']}\")\n",
    "    print(f\"Kraken price: ${future2.result()['close']}\")\n",
    "    print(\"Waited on result: done?\", future1.done())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Executor .map()\n",
    "\n",
    "While you can perfectly well call `.submit()` manually to create many futures, very often it is easier and more clear to create an entire family of implicit futures for different data you wish to process concurrently.  \n",
    "\n",
    "When using `.map()` to create families of workers, you may only pass a single argument.  This simply means you have to package each *data value* into a collection like a tuple or dictionary that can be destructured within the worker function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def check_price(data):\n",
    "    exchange, symbol, date = data\n",
    "    url = f\"{base_url}/price/{exchange}/{symbol}/{date}\"\n",
    "    resp = requests.get(url)\n",
    "    return resp.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When you call `.map()` it is as if you called `.result()` on each future, although the futures are not named."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 records retrieved\n",
      "[6409.8, 133, 39.076, 6630.8, 135.49, 39.356, 6803.9, '...']\n",
      "CPU times: user 150 ms, sys: 66.1 ms, total: 216 ms\n",
      "Wall time: 1.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "datasets = []\n",
    "for exchange in ['bitfinex', 'bitstamp', 'kraken']:\n",
    "    for date in ['2020-04-01', '2020-04-02', '2020-04-03', '2020-04-04']:\n",
    "        for coin in ['btc', 'eth', 'ltc']:\n",
    "            datasets.append((exchange, coin, date))\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=100) as ex:\n",
    "    results = ex.map(check_price, datasets)\n",
    "    prices = [price['close'] for price in results]\n",
    "    print(f\"{len(prices)} records retrieved\")\n",
    "    print(prices[:7] + [\"...\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Futures as_completed()\n",
    "\n",
    "The `.map()` method is very concise for mapping one function to multiple data sets it should process.  However, it *did* require us to refactor the function to unpack a single *data* object.  A bit more flexible is using the function `as_completed()` to iterate over results as they become available.  This will block on the next result becoming available, but the threads or processes generating those results will keep running while your code handles an available one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 records retrieved\n",
      "CPU times: user 159 ms, sys: 109 ms, total: 269 ms\n",
      "Wall time: 1.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with ThreadPoolExecutor(max_workers=100) as ex:\n",
    "    # Could add futures with different function/arguments\n",
    "    futures = {ex.submit(check_price, data): None for data in datasets}\n",
    "    records = []\n",
    "    for future in cf.as_completed(futures):\n",
    "        records.append(future.result()['close'])\n",
    "        \n",
    "print(f\"{len(records)} records retrieved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Producer/Consumer Pattern\n",
    "\n",
    "What we did so far supposed that we knew the data associated with our overall processing in advance of launching workers.  That will not always be the case; in particular, some workers may generate the data for other workers to process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The trick to allowing this setup is the use of **queues** (or a similar data structure) that allow safe concurrent access.  That is, a queue allows one worker to push data into a collection, and another worker to pop data, without risking one overwriting the other or other data integrity problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We will extend the example of querying priceses from exchanges, but with the addition of a **producer** that generates requests at the same time as other **consumers** are processing them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The architecture of this example is a bit more detailed, to resemble real programs you will write.  We will launch three types of tasks as part of this overall system.\n",
    "\n",
    "* A **monitor** that will simply show the evolving queues\n",
    "* A **producer** that will feed requests into the TODO queue\n",
    "* Multiple **consumers** that will act on requests, and add to the RESULTS queue\n",
    "\n",
    "Let us first create the queues that the tasks will work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Q_todo, Q_results, Q_info = Queue(), SimpleQueue(), SimpleQueue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "While it might be more robust to put the initial introspection of the server into a concurrent task, here we simplify slightly and perform this small task in a non-concurrent way first.  The server can report what exchanges and symbols are available for querying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462 total queries will be performed\n"
     ]
    }
   ],
   "source": [
    "# Find exchanges and symbols from the server\n",
    "exchanges = requests.get(f\"{base_url}/exchanges\").json()\n",
    "symbols = requests.get(f\"{base_url}/symbols\").json()\n",
    "\n",
    "# Choose the dates of interest ourselves\n",
    "dates, start = [], datetime(2020, 3, 1) \n",
    "for i in range(14):\n",
    "    date = start + timedelta(days=i)\n",
    "    dates.append(date.strftime('%Y-%m-%d'))\n",
    "\n",
    "nreqs = len(exchanges)*len(dates)*len(symbols)\n",
    "print(f\"{nreqs} total queries will be performed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Next let us define the monitor that simply reports progress. This uses some magic with IPython widgets that are not the subject of this lesson, so do not worry about those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def monitor(Q_todo, Q_results, Q_info):\n",
    "    # Create the visual monitor widgets\n",
    "    todo = IntProgress(value=0, min=0, max=nreqs, step=1, \n",
    "                description='TODO', orientation='horizontal', \n",
    "                bar_style='info', layout=Layout(width='50%'))\n",
    "    done = IntProgress(value=0, min=0, max=nreqs, step=1, \n",
    "                description='DONE', orientation='horizontal', \n",
    "                bar_style='success', layout=Layout(width='50%'))\n",
    "    info = Label(value='STARTING...')\n",
    "    display(todo); display(done); display(info)\n",
    "    \n",
    "    while True:\n",
    "        todo.value = Q_todo.qsize()\n",
    "        done.value = Q_results.qsize()\n",
    "        try:\n",
    "            info.value = f\"{Q_info.get(timeout=3)}\"\n",
    "        except Empty:\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We need to create a producer function that will feed queries into the TODO queue.  In this case, the data involved is a small tuple of query elements; in other cases, the data itself might be substantial (such as a numeric array or a large text).  This producer artificially limits the rate at which it adds to the queue just to simulate real-world applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def producer(Q_todo, Q_info, exchanges, dates, symbols):\n",
    "    Query = namedtuple('Query', 'exchange date symbol')\n",
    "    for exchange in exchanges:\n",
    "        for date in dates:\n",
    "            for symbol in symbols:\n",
    "                query = Query(exchange, symbol, date)\n",
    "                Q_todo.put(query)\n",
    "                Q_info.put(f\"ADDING {query}\")\n",
    "                sleep(0.04)  # Artificial small delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The final piece of our in our task scaffolding is the worker function.  The job of this is to consume unprocessed queries from the TODO queue, operate on them, and put the result in the RESULTS queue.  The RESULTS queue is a regular `Queue` rather than a `SimpleQueue` because a worker/consumer will mark the query as processed at the end of its work, using the `.task_done()` method (not available in `SimpleQueue`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def worker(Q_todo, Q_results, Q_info):\n",
    "    thread = current_thread().name\n",
    "    while not Q_todo.empty():\n",
    "        query = Q_todo.get()\n",
    "        Q_info.put(f\"PROCESSING {query}\")\n",
    "        result = check_price(query)\n",
    "        Q_results.put(result)\n",
    "        Q_todo.task_done()\n",
    "        \n",
    "    Q_info.put(f\"EXITING {thread} (TODO queue empty)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Putting it together, let us launch our concurrent processing using many threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4099beaed3482980edbfe9a069ca1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, bar_style='info', description='TODO', layout=Layout(width='50%'), max=462)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8262a1b783d4f328bcf7d89428ed6d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, bar_style='success', description='DONE', layout=Layout(width='50%'), max=462)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aadbaedbe05432393699c2c76b5e1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='STARTING...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "Q_todo, Q_results, Q_info = Queue(), SimpleQueue(), SimpleQueue()\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=100) as ex:\n",
    "    futures = []\n",
    "    futures.append(ex.submit(producer, Q_todo, Q_info, exchanges, dates, symbols))\n",
    "    futures.append(ex.submit(monitor, Q_todo, Q_results, Q_info))\n",
    "    for _ in range(32):\n",
    "        futures.append(ex.submit(worker, Q_todo, Q_results, Q_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Having run our processing across concurrent workers, for this purpose, we have accumulated all the results in the RESULTS queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All futures done? True\n",
      "Size of TODO: 0\n",
      "Size of RESULTS: 0\n",
      "Size of INFO: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"All futures done?\", all([f.done() for f in futures]))\n",
    "\n",
    "print(\"Size of TODO:\", Q_todo.qsize())\n",
    "print(\"Size of RESULTS:\", Q_results.qsize())\n",
    "print(\"Size of INFO:\", Q_info.qsize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "From the queue, we might want to pull the results into random access data structure.  For a few hundred elements, certainly this is convenient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0a71406c441d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/INE/lib/python3.8/random.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample larger than population or is negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0msetsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m21\u001b[0m        \u001b[0;31m# size of a small set minus size of an empty list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "while True:\n",
    "    try:\n",
    "        results.append(Q_results.get(block=None))\n",
    "    except Empty:\n",
    "        break\n",
    "        \n",
    "sample(results, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "The `concurrent.futures` module is the most abstract, highest level concurrency module in the Python standard library and **it SHOULD be your default option** when writing concurrent code.  Only when you need more advanced capabilities, will you need to use the `threading` or `multiprocessing` modules directly."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
