{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python DB-API\n",
    "\n",
    "Python defines a standard interface for all SQL relational database system, called the DB-API.  Most database drivers within the Python ecosystem follow this API standard; any features specific to a particular Relational Database Management System (RDBMS), such as PostgreSQL, are communicated at the SQL level rather than with special Python methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python Enhancement Proposal (PEP) 249 describes the requirements of the DB-API 2.0.  Details of the degree of support and choice among optional features are exposed in module interfaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapter capabilities\n",
    "\n",
    "For comparison, let us inspect adapters to an SQLite database and a PostgreSQL database.  Some parameters are coded compactly.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| threadsafety | Meaning\n",
    "|-------------:|:--------------------------------------\n",
    "| 0            | Threads may not share the module.\n",
    "| 1            | Threads may share the module, but not connections.\n",
    "| 2            | Threads may share the module and connections.\n",
    "| 3            | Threads may share the module, connections and cursors.\n",
    "\n",
    "---\n",
    "\n",
    "| paramstyle | Meaning\n",
    "|-----------:|:----------------------------------------\n",
    "| qmark      | Question mark style, e.g. ...WHERE name=?\n",
    "| numeric    | Numeric, positional style, e.g. ...WHERE name=:1\n",
    "| named      | Named style, e.g. ...WHERE name=:name\n",
    "| format     | ANSI C printf format codes, e.g. ...WHERE name=%s\n",
    "| pyformat   | Python extended format codes, e.g. ...WHERE name=%(name)s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "print(f\"API level       | {sqlite3.apilevel}\")\n",
    "print(f\"Parameter style | {sqlite3.paramstyle}\")\n",
    "print(f\"Thread safety   | {sqlite3.threadsafety}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "print(f\"API level       | {psycopg2.apilevel}\")\n",
    "print(f\"Parameter style | {psycopg2.paramstyle}\")\n",
    "print(f\"Thread safety   | {psycopg2.threadsafety}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A connection and cursors\n",
    "\n",
    "We can see from the threadsafety level our `psycopg2` adapter provides, that we can create a single connection for all the threads we may wish to use.  The cursors should remain distinct between threads.  This lesson will not use Python threading, which is a separate course, but we can create multiple cursors in the main thread, if we wish.  For this lesson, we simply assume that a database called `ine` exists, and the PostgreSQL user and password configured will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'ine_student'\n",
    "pwd = 'ine-password'\n",
    "host = 'localhost'\n",
    "port = '5432'\n",
    "db = 'ine'\n",
    "conn = psycopg2.connect(database=db, host=host, user=user, password=pwd, port=port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it is convenient, we can work with multiple cursor.  Keep in mind, however, that performing a commit or a rollback will happen at the connection level.  However, it may be useful, for example, to create temporary cursors within a function, and only pass around a connection object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main action we peform with a cursor is to `.execute()` SQL statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the table with cursor#1\n",
    "sql_create = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS users (\n",
    "  user_id SERIAL PRIMARY KEY,\n",
    "  username VARCHAR(50) UNIQUE NOT NULL,\n",
    "  password VARCHAR(50) NOT NULL,\n",
    "  age SMALLINT,\n",
    "  created_on TIMESTAMP NOT NULL\n",
    ");\n",
    "\"\"\"\n",
    "cur.execute('DROP TABLE IF EXISTS users;')\n",
    "cur.execute(sql_create)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PostgreSQL allows an SQL extension of `IF NOT EXISTS` in SQL statements.  The table may or may not have existed initially, but this will not fail if it did.  However, if a table already exists, a second `CREATE TABLE` with this option will ignore the field names and data types in the new SQL statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the table has not actually been created, but rather the action has been placed in the transaction queue.  It may or may not be committed.  In fact, if we attempt to commit it, it is *possible* that some other action by another connection would be inconsistent with this, and the transaction would be rolled back.  In this case, and most cases, a commit will succeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described, a `CREATE TABLE IF NOT EXISTS` can succeed at the query level, but not alter a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_bad_create = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS users (\n",
    "  not_an_id SERIAL PRIMARY KEY,\n",
    "  not_a_user INTEGER UNIQUE NOT NULL,\n",
    "  not_a_password VARCHAR(30) NOT NULL\n",
    ");\n",
    "\"\"\"\n",
    "cur.execute(sql_bad_create)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the table structure using a query, and verify which version exists in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_schema = \"\"\"\n",
    "SELECT column_name, data_type, character_maximum_length, \n",
    "       column_default, is_nullable\n",
    "FROM INFORMATION_SCHEMA.COLUMNS \n",
    "WHERE table_name = 'users';\n",
    "\"\"\"\n",
    "cur.execute(sql_schema)\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with data\n",
    "\n",
    "With the table we created above, let us write some data to it.  Remember that the `pscyopg2` adapter uses the `pyformat` parameter style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def add_user(conn, user):\n",
    "    # We make a new cursor every time this function is called\n",
    "    # ... would work even if the function was called per-thread\n",
    "    cursor = conn.cursor()\n",
    "    user['now'] = datetime.now().isoformat()\n",
    "    user['age'] = user.get('age')\n",
    "    sql = \"\"\"INSERT INTO users (username, password, age, created_on) \n",
    "             VALUES (%(username)s, %(password)s, %(age)s, %(now)s)\"\"\"\n",
    "    cursor.execute(sql, user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call this function with user data a few times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_info = [\n",
    "  dict(username='Alice', password='bad_pw_1', age=37),\n",
    "  dict(username='Bob', password='bad_pw_2'),\n",
    "  dict(username='Carlos', password='bad_pw_3', age=62)\n",
    "]\n",
    "for user_info in users_info:\n",
    "    add_user(conn, user_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, so good.  However, these data have not actually been stored in the database, only queued as a transaction.  The current cursor sees them as present, but another cursor will not yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT * FROM users;\")\n",
    "for row in cur:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn2 = psycopg2.connect(database=db, host=host, user=user, password=pwd, port=port)\n",
    "cur2 = conn2.cursor()\n",
    "cur2.execute(\"SELECT * FROM users;\")\n",
    "cur2.fetchmany(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the data available to all connections, we want to commit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "cur2.execute(\"SELECT * FROM users;\")\n",
    "print(cur2.fetchone())\n",
    "print(next(cur2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncommitted data\n",
    "\n",
    "A batch of SQL statements may not succeed.  In such a case, we may not wish for *any* of them to be recorded.  In such a case, we want to call `.rollback()` on the connection to inform the server to discard the transaction from the queue.  We might rollback because of a problem the server reports, or we may do so because of something we determine at an application level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_many(conn, users_info):\n",
    "    try:\n",
    "        for user_info in users_info:\n",
    "            if 'password' in user_info['password']:\n",
    "                raise ValueError(f\"Terrible password for {user_info['username']}\")\n",
    "            add_user(conn, user_info)\n",
    "    except Exception as err:\n",
    "        conn.rollback()\n",
    "        print(\"Transaction rolled back because of:\", type(err).__name__)\n",
    "        print(err)\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps the datatypes are wrong:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_bad_data = [\n",
    "    dict(username='Dave', password='insecure_1'),\n",
    "    dict(username='Erin', password='insecure_2'),\n",
    "    dict(username='Faythe', password='insecure_3', age=\"ABC\")\n",
    "]\n",
    "add_many(conn, users_bad_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or perhaps a uniqueness constraint is violated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_dup_data = [\n",
    "    dict(username='Dave', password='insecure_1'),\n",
    "    dict(username='Erin', password='insecure_2'),\n",
    "    dict(username='Carlos', password='bad_pw_4')\n",
    "]\n",
    "add_many(conn, users_dup_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or it might be that the application itself is able to exclude some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_app_rules = [\n",
    "    dict(username='Grace', password='insecure_77'),\n",
    "    dict(username='Heidi', password='insecure_88'),\n",
    "    dict(username='Ivan', password='password_55')\n",
    "]\n",
    "add_many(conn, users_app_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working in batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the last few cells, we will configure the connection to AUTOCOMMIT.  That is, every time an insertion is made, a COMMIT is implictly performed afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.set_session(autocommit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen several ways to fetch the results from a query.  We can use `.fetchone()`, or `.fetchmany()`, or `.fetchall()`.  We can also loop over the cursor object to bind each row, or using the same Python iterator protocol, call `next(cursor)`.\n",
    "\n",
    "A similar capability is available for excucting statements.  In concept, this could be many SELECT queries, but more commonly, it is many INSERT or UPDATE commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now().isoformat()\n",
    "users_more = [\n",
    "    dict(username='Sybil', password='M7c&sd31&0hA', age=44, created_on=now),\n",
    "    dict(username='Trudy', password='y9bD6SA2O%$t', age=22, created_on=now),\n",
    "    dict(username='Vanna', password='9$Ts9HK*3!tR', age=55, created_on=now)\n",
    "]\n",
    "sql = \"\"\"\n",
    "INSERT INTO users (username, password, age, created_on) \n",
    "VALUES (%(username)s, %(password)s, %(age)s, %(created_on)s)\n",
    "\"\"\"\n",
    "cur.executemany(sql, users_more)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, you probably want to catch exceptions and do conditional rollbacks and remediation around your `.executemany()` calls.  But we assume it succeeded, and was automatically committed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying it again, we can explicitly ask for details on the columns returned by a query, and the number of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('SELECT user_id, username, age FROM users;')\n",
    "for item in cur.description:\n",
    "    print(item)\n",
    "print(\"Rows returned:\", cur.rowcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to notice is that the SERIAL `user_id` column was incremented on the various failures that were not committed.  This makes sense since a unique sequential number has to be assigned before the server can know whether that transaction will be committed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "To use adapters that follow the DB-API requires learning only a few fairly simple APIs, while offering flexibility at the Python level.  Once you have mastered that, everything else you really need to know is specific to PostgreSQL as an RDBMS, and is accessed via SQL interfaces rather than Python functions or methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
