{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# File Formats\n",
    "\n",
    "There are many specialized file formats, used by many applications.  The Python standard library comes with support for a reasonable number of them, but for other purposes, various third-party libraries are needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Not all the formats that Python supports out of the box are discussed in this course, but many are in this series.  For example, internet-oriented formats like those used for email and HTML web pages are in other courses.  JSON and XML are discussed in the Data Serialization course.  A few others in the standard library are relatively uncommon or are old."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Module: csv\n",
    "\n",
    "The course on Data Serialization with Python deals with CSV in more detail.  But given the ubiquity of delimited files, we look at it very briefly here.  Let us look at a couple examples of reading from CSV, and one of writing to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      tweet_id: 570306133677760513\n",
      "             airline_sentiment: neutral\n",
      "  airline_sentiment_confidence: 1.0\n",
      "                negativereason: \n",
      "     negativereason_confidence: \n",
      "                       airline: Virgin America\n"
     ]
    }
   ],
   "source": [
    "with open('Airline-Tweets.csv') as fh:\n",
    "    airline = csv.reader(fh)\n",
    "    headers = next(airline)\n",
    "    for tweet in airline:\n",
    "        for field, value, _ in zip(headers, tweet, range(6)):\n",
    "            print(f\"{field:>30}: {value}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'airline': 'Virgin America',\n",
      " 'airline_sentiment': 'neutral',\n",
      " 'airline_sentiment_confidence': '1.0',\n",
      " 'airline_sentiment_gold': '',\n",
      " 'name': 'cairdin',\n",
      " 'negativereason': '',\n",
      " 'negativereason_confidence': '',\n",
      " 'negativereason_gold': '',\n",
      " 'retweet_count': '0',\n",
      " 'text': '@VirginAmerica What @dhepburn said.',\n",
      " 'tweet_coord': '',\n",
      " 'tweet_created': '2015-02-24 11:35:52 -0800',\n",
      " 'tweet_id': '570306133677760513',\n",
      " 'tweet_location': '',\n",
      " 'user_timezone': 'Eastern Time (US & Canada)'}\n"
     ]
    }
   ],
   "source": [
    "with open('Airline-Tweets.csv') as fh:\n",
    "    airline = csv.DictReader(fh, quoting=csv.QUOTE_MINIMAL)\n",
    "    pprint(tweet := next(airline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's define some simple data that we would like to write out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fields = [\"Name\", \"Evaluation\", \"Rating\", \"Age\"]\n",
    "data = [\n",
    "    [\"Mia Johnson\", \"The movie was excellent\", 9.5, 25],\n",
    "    [\"Liam Lopez\", \"Didn't really like it\", 3.0, 35],\n",
    "    [\"Isabella Lee\", \"Wow! That was great\", 8.0, 45]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can write our in-memory data as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Name\",\"Evaluation\",\"Rating\",\"Age\"\n",
      "\"Mia Johnson\",\"The movie was excellent\",9.5,25\n",
      "\"Liam Lopez\",\"Didn't really like it\",3.0,35\n",
      "\"Isabella Lee\",\"Wow! That was great\",8.0,45\n"
     ]
    }
   ],
   "source": [
    "with open('tmp-movie.csv', 'w') as fh:\n",
    "    movie = csv.writer(fh, quoting=csv.QUOTE_NONNUMERIC)\n",
    "    for record in [fields]+data:\n",
    "        movie.writerow(record)\n",
    "        \n",
    "!cat tmp-movie.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Module: pickle\n",
    "\n",
    "The pickle format is a special, Python-specific, data format that serializes arbitrary Python objects.  It is discussed in much more detail in the Data Serialization course.  Almost any Python object can be written to disk and read back later (or shared, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let us use the first tweet from the last section, which is represented as a dictionary.  The function `dump()` writes to a file while `dumps()` creates a bytestring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x80\\x04\\x95\\xb6\\x01\\x00\\x00\\x00\\x00\\x00\\x00}\\x94(\\x8c\\x08tweet_id\\x94\\x8c\\x12570306133677760513\\x94\\x8c\\x11airline_sentiment\\x94\\x8c\\x07neutral\\x94\\x8c\\x1cairline_sentiment_confidence\\x94\\x8c\\x031.0\\x94\\x8c\\x0enegativereason\\x94\\x8c\\x00\\x94\\x8c\\x19negativereason_confidence\\x94h\\x08\\x8c\\x07airline\\x94\\x8c\\x0eVirgin America\\x94\\x8c\\x16airline_sentiment_gold\\x94h\\x08\\x8c\\x04name\\x94\\x8c\\x07cairdin\\x94\\x8c\\x13negativereason_gold\\x94h\\x08\\x8c\\rretweet_count\\x94\\x8c\\x010\\x94\\x8c\\x04text\\x94\\x8c#@VirginAmerica What @dhepburn said.\\x94\\x8c\\x0btweet_coord\\x94h\\x08\\x8c\\rtweet_created\\x94\\x8c\\x192015-02-24 11:35:52 -0800\\x94\\x8c\\x0etweet_location\\x94h\\x08\\x8c\\ruser_timezone\\x94\\x8c\\x1aEastern Time (US & Canada)\\x94u.'\n"
     ]
    }
   ],
   "source": [
    "with open('tmp-tweet.pkl', 'wb') as fh:\n",
    "    pickle.dump(tweet, fh)\n",
    "\n",
    "print(pickle.dumps(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For reading we have `load()` versus `loads()` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'airline': 'Virgin America',\n",
      " 'airline_sentiment': 'neutral',\n",
      " 'airline_sentiment_confidence': '1.0',\n",
      " 'name': 'cairdin',\n",
      " 'retweet_count': '0',\n",
      " 'text': '@VirginAmerica What @dhepburn said.',\n",
      " 'tweet_created': '2015-02-24 11:35:52 -0800',\n",
      " 'tweet_id': '570306133677760513',\n",
      " 'user_timezone': 'Eastern Time (US & Canada)'}\n"
     ]
    }
   ],
   "source": [
    "with open('tmp-tweet.pkl', 'rb') as fh:\n",
    "    new = pickle.load(fh)\n",
    "    pprint({k:v for (k,v) in new.items() if v})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Compression Formats\n",
    "\n",
    "A number of standard library modules deal with the most popular compression techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Module: gzip\n",
    "\n",
    "The `gzip` module is often used to handle files using the widespread `.gz` compression suffix.  The underlying file might be of any type; this format merely describes is manner of compression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This module can actually compress within memory, and not only to and from files.  Sometimes this is useful for data being transmitted over the wire, for example.  Most of the time, data read from or written to files is what you care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "from pathlib import Path\n",
    "tweets = Path('Airline-Tweets.csv')\n",
    "gzfile = Path('tmp-tweets.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A quick look at the in-memory compression first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bytes: 1004\n",
      "Initial: b'\\x1f\\x8b\\x08\\x00/\\xf0N_\\x02\\xff\\xed\\xc1\\x81\\x00\\x00\\x00\\x00\\xc3 \\xb6'\n"
     ]
    }
   ],
   "source": [
    "data = b'A'*1_000_000\n",
    "small = gzip.compress(data)\n",
    "print(\"Bytes:\", len(small))\n",
    "print(\"Initial:\", small[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let us compress a file.  We use the large CSV of Tweets used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 220 ms, sys: 8.23 ms, total: 228 ms\n",
      "Wall time: 228 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with gzip.open(gzfile, 'w') as gz:\n",
    "    data = tweets.read_bytes()\n",
    "    gz.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Raw size: 3,421,431\n",
      "Compressed: 1,118,042\n"
     ]
    }
   ],
   "source": [
    "print(f\"  Raw size: {tweets.stat().st_size:,}\")\n",
    "print(f\"Compressed: {gzfile.stat().st_size:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Module: bz2\n",
    "\n",
    "The `bz2` module is very similar to the `gzip` module, just using a different underlying compression technique.  Most of the time, `.bz2` files are smaller than `.gz` equivalents, but take longer to compress and decompress.  Usually your concern will be dealing with the format you get, not weighing these trade-offs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import bz2\n",
    "bzfile = Path('tmp-tweets.csv.bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A quick look at the in-memory compression first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bytes: 48\n",
      "Initial: b'BZh91AY&SY\\x12\\xa5~<\\x00\\x07\\xa8\\x84@\\xa0'\n"
     ]
    }
   ],
   "source": [
    "data = b'A'*1_000_000\n",
    "small = bz2.compress(data)\n",
    "print(\"Bytes:\", len(small))\n",
    "print(\"Initial:\", small[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let us compress the large CSV of Tweets used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 503 ms, sys: 4.15 ms, total: 507 ms\n",
      "Wall time: 506 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with bz2.open(bzfile, 'w') as bz:\n",
    "    data = tweets.read_bytes()\n",
    "    bz.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Raw size: 3,421,431\n",
      "Compressed: 796,184\n"
     ]
    }
   ],
   "source": [
    "print(f\"  Raw size: {tweets.stat().st_size:,}\")\n",
    "print(f\"Compressed: {bzfile.stat().st_size:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Module: lzma\n",
    "\n",
    "The `lzma` module implements a still newer algorithm than `gzip` and `bz2`.  The tool `xz` and the older tool `lzma` use this format, as do a variety of other wrapping applications.  As a rule of thumb, `lzma` can often do slightly better than `bz2` in degree of compression; but is far slower than `gzip`, or even `bz2`.  Details vary with the kind of data you work with though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import lzma\n",
    "xzfile = Path('tmp-tweets.csv.xz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A quick look at the in-memory compression first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bytes: 276\n",
      "Initial: b'\\xfd7zXZ\\x00\\x00\\x04\\xe6\\xd6\\xb4F\\x02\\x00!\\x01\\x16\\x00\\x00\\x00'\n"
     ]
    }
   ],
   "source": [
    "data = b'A'*1_000_000\n",
    "small = lzma.compress(data)\n",
    "print(\"Bytes:\", len(small))\n",
    "print(\"Initial:\", small[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let us compress the large CSV of Tweets used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.12 s, sys: 56.3 ms, total: 2.18 s\n",
      "Wall time: 2.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with lzma.open(xzfile, 'w', format=lzma.FORMAT_XZ) as xz:\n",
    "    data = tweets.read_bytes()\n",
    "    xz.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Raw size: 3,421,431\n",
      "Compressed: 843,276\n"
     ]
    }
   ],
   "source": [
    "print(f\"  Raw size: {tweets.stat().st_size:,}\")\n",
    "print(f\"Compressed: {xzfile.stat().st_size:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Module: zipfile\n",
    "\n",
    "The other compression modules we saw in the Python standard library are just about compression formats.  The module `zipfile` works with an actual archive format that might contain files compressed using any of the compression formats described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('tmp-example.zip', 'w') as zf:\n",
    "    zf.write('tmp-movie.csv')\n",
    "    zf.write(tweets, compress_type=zipfile.ZIP_DEFLATED)\n",
    "    zf.write('02-File-Formats.ipynb', \n",
    "                     compress_type=zipfile.ZIP_LZMA, \n",
    "                     compresslevel=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Usually you want to work with an existing zip archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         tmp-movie.csv: 174 ⟶ 174\n",
      "    Airline-Tweets.csv: 3,421,431 ⟶ 1,138,002\n",
      " 02-File-Formats.ipynb: 24,841 ⟶ 4,927\n"
     ]
    }
   ],
   "source": [
    "with zipfile.ZipFile('tmp-example.zip') as zf:\n",
    "    for info in zf.infolist():\n",
    "        print(f\"{info.filename:>22}: {info.file_size:,} ⟶ {info.compress_size:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example, to work with one file inside the archive, just as if it were a plain file on disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Name\",\"Evaluation\",\"Rating\",\"Age\"\n",
      "\"Mia Johnson\",\"The movie was excellent\",9.5,25\n",
      "\"Liam Lopez\",\"Didn't really like it\",3.0,35\n",
      "\"Isabella Lee\",\"Wow! That was great\",8.0,45\n"
     ]
    }
   ],
   "source": [
    "with zipfile.ZipFile('tmp-example.zip') as zf:\n",
    "    with zf.open('tmp-movie.csv') as movie:\n",
    "        for line in movie:\n",
    "            print(line.decode(), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Module: sqlite3\n",
    "\n",
    "SQLite is a lightweight disk-based database, where all tables, indices, etc. live inside a single file.  For the most part, the module `sqlite3` follows the same DB-API used to access multi-user RDBMSs within Python.  The sqlite3 data format is broadly used: for example, it is utilized on the largest supercompters for local storage and also on every iOS and Android device in the world as part of their operating system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As an example, the same collection of tweets about airlines we have used earlier, was distributed by Kaggle in sqlite3 format along with CSV (with sqlite3 being the preferred choice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('Airline-Tweets.sqlite')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Tweets',)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('SELECT name FROM sqlite_master WHERE type=\"table\"')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(567845681768968192, 'positive', 1, '', '', 'Southwest', '', 'beccalauren2011', '', 0, '@SouthwestAir I got it added thank you! :)', '', '2015-02-17 16:38:55 -0800', 'SMALL TOWN, USA', 'Central Time (US & Canada)')\n",
      "(567845726220357632, 'neutral', 0.6601, '', '', 'Virgin America', '', 'josiebarosie', '', 0, '@VirginAmerica is that #thestarter??😁', '', '2015-02-17 16:39:05 -0800', 'Cork.Ireland', '')\n"
     ]
    }
   ],
   "source": [
    "cur.execute('SELECT * FROM Tweets LIMIT 2 OFFSET 1000')\n",
    "for row in cur:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It is sometimes friendlier to return dictionary-like rows as results to see what column names correspond to values.  This special `Row` object allows access by both column name and position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tweet_id',\n",
       " 'airline_sentiment',\n",
       " 'airline_sentiment_confidence',\n",
       " 'negativereason',\n",
       " 'negativereason_confidence',\n",
       " 'airline',\n",
       " 'airline_sentiment_gold',\n",
       " 'name',\n",
       " 'negativereason_gold',\n",
       " 'retweet_count',\n",
       " 'text',\n",
       " 'tweet_coord',\n",
       " 'tweet_created',\n",
       " 'tweet_location',\n",
       " 'user_timezone']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.row_factory = sqlite3.Row\n",
    "cur = conn.cursor()\n",
    "cur.execute('SELECT * FROM Tweets WHERE airline_sentiment=\"positive\"')\n",
    "row = cur.fetchone()\n",
    "row.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567655489119326209\n",
      "('Southwest', '', 'rjp1208')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tweet_id': 567655489119326209,\n",
       " 'airline_sentiment': 'positive',\n",
       " 'airline_sentiment_confidence': 1,\n",
       " 'negativereason': '',\n",
       " 'negativereason_confidence': '',\n",
       " 'airline': 'Southwest',\n",
       " 'airline_sentiment_gold': '',\n",
       " 'name': 'rjp1208',\n",
       " 'negativereason_gold': '',\n",
       " 'retweet_count': 0,\n",
       " 'text': '@SouthwestAir nice work on the update!',\n",
       " 'tweet_coord': '',\n",
       " 'tweet_created': '2015-02-17 04:03:09 -0800',\n",
       " 'tweet_location': '',\n",
       " 'user_timezone': 'Pacific Time (US & Canada)'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(row['tweet_id'])\n",
    "print(row[5:8])\n",
    "dict(row)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
